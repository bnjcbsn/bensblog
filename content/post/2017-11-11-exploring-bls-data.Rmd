---
title: "Exploring BLS Data to Create My Own Jobs Report"
author: "Ben Jacobson"
date: '2017-11-11'
slug: exploring-bls-data
tags: BLS
categories: ["Draft"]
---
```{r include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)
```
# The BLS data availability  
I became curious about this subject following a tweet by a bank with an [infographic](http://ei.marketwatch.com//Multimedia/2016/12/02/Photos/ZH/MW-FB220_jobs_g_20161202093708_ZH.jpg?uuid=cd745c42-b89c-11e6-9b93-001cc448aede) regarding the November jobs report. I did a quick web search a day later and decided to make a project of this chart from [here](https://resources.onewire.com/finance-industry-news/november-jobs-report-falls-short-expectations/).  
![](/MW_MonthlyJobs.jpg)
It dawned on me this public data may prove useful for a post as my professional work is entirely not public for sharing. I visited bls.gov (Bureau of Labor Statistics) to try to find out what is available and how to access it. The BLS offers a web interface, an API, and simple text files for accessing the data they routiely publish. To select a launching point, I always start out with a Google query and stackoverflow search. In top results, I discovered a package developed for BLS data access that was created by Kris Eberwein, [blscrapeR](https://cran.r-project.org/web/packages/blscrapeR/index.html).  
https://cran.r-project.org/web/packages/blscrapeR/vignettes/Employment_and_Unemployment.html

The BLS site does offer text file downloads, and Kris' package uses that approach, but seems centered on using the API for the site which I will lean away from if possible. I'm still trying to understand any benefits gained from either method over the other.   

# Download BLS data  
From the web search, a solution result that I chose is a stackoverflow [post](https://stackoverflow.com/questions/36504590/reading-simple-text-file-into-r-bls-data) regarding how to read BLS text data directly in to R. This approach uses the text files published by the BLS and doesn't require their API. For simplicity, I decide to pursue this and table the API approach.  

My first attempt to download follows. Notice that I've loaded no packages yet. This is base R. I carelessly copy in some code from the previous post and make an error.
```{r, eval=FALSE}
url <- "http://download.bls.gov/pub/time.series/oe/oe.datatype"
header <- read.delim(url, nrows = 1, header = FALSE, stringsAsFactors = FALSE)
names(df) <- header
head(df)
```

[Error in read.table(file = file, header = header, sep = sep, quote = quote, : no lines available in input]

I'll try that again, but include all results.

```{r, eval=FALSE}
url <- "http://download.bls.gov/pub/time.series/oe/oe.datatype"
dat <- read.delim(url, stringsAsFactors = FALSE)
head(dat)
```

Hmmm, what if I skip the first row?
```{r, eval=FALSE}
url <- "http://download.bls.gov/pub/time.series/oe/oe.datatype"
dat <- read.delim(url, skip = 1, stringsAsFactors = FALSE)
head(dat)
```

It becomes apparent to me that in my first successful read, the row names are actually the first column. I don't expect to see this and the SO post doesn't identify this. But the SO solution does make more sense to address this. I'm curious at this point about how to define this structure. I want the results of the first read, but with the row names in the first column and the first column in the second column.

Shit! All of a sudden, I can't download anything, drawing an error instead. [Error in read.table(file = file, header = header, sep = sep, quote = quote, : no lines available in input] Back to kuberwein's discussion. 

Observing this code for inflation.R:
```{r}
#Load file from BLS servers
temp <- tempfile()
# Add urlEXists here.
download.file("https://download.bls.gov/pub/time.series/cu/cu.data.1.AllItems",temp)
unlink(temp)
```

That worked!

What gives here? I have no idea why read.delim was working and then began failing. I may return to that at some point in the future.

Let's try a package, turning straight to the tidyverse. This first attempt works, but doesn't produce appropriate results.

```{r, eval=FALSE}
library(tidyverse)
df <- read_delim(url, delim = "\t")
head(df)
```
I researched my tidyverse options and decided to give readr::read_tsv a try.
```{r}
library(tidyverse)
url <- "https://download.bls.gov/pub/time.series/ce/ce.datatype"
datatype <- read_tsv(url)
head(datatype)
```

I'm not sure what's going on here because there are loads of messages but the results look complete. I'm switching to readr::read_tsv from this point for loading these files. Moving along...  

There is extensive information provided by BLS on their text files found  [here](https://download.bls.gov/pub/time.series/ce/ce.txt), of course, in text form. The full list of text files available are found [here](https://download.bls.gov/pub/time.series/ce/).  

Continuing, let's retrieve the employment series data dictionary:  

```{r}
library(tidyverse)
url <- "https://download.bls.gov/pub/time.series/ce/ce.series"
series <- read_tsv(url)
head(series)
```

Then download all series data, except that this fails in website render, perhaps due to size (not immediately concerned with solving if the next approach works):

```{r, eval=FALSE}
library(tidyverse)
url <- "https://download.bls.gov/pub/time.series/ce/ce.data.0.AllCESSeries"
allseries <- read_tsv(url)
head(allseries)
```

I'm interested in the first record of the series data, `r series[1,6]`, so I decide to scale back. Instead of all data, I'll download just the series that I'm seeking for this exercise.  
```{r}
library(tidyverse)
url <- "https://download.bls.gov/pub/time.series/ce/ce.data.01a.CurrentSeasAE"
series.01a <- read_tsv(url)
head(series.01a)
```

My next steps will be to evaluate the data, convert this to a time series, then create a plot.  

## Data Evaluation  

```{r}
glimpse(series.01a)
```
```{r}
summary(series.01a)
```

```{r plot1}
ggplot(series.01a, aes(x=year, y=value, colour=as.factor(series_id))) +
    geom_violin()
```

Oh, that's not entirely what I expected because I thought the description indicated this text file would be a single series. I need to understand why I have many series IDs eventually. Let's replot on the first series ID, CES0000000001. I'll replot and factor on year since I know that only one series is present.

```{r plot2}
series.01a %>%
    filter(series_id=='CES0000000001') %>%
ggplot(aes(x=year, y=value, colour=as.factor(year))) +
    geom_violin()
```

```{r plot3}
series.01a %>%
    filter(series_id=='CES0000000001') %>%
ggplot(aes(x=year, y=value, colour=as.factor(period))) +
    geom_violin()
```

My suspicion is that this subset is unique on year and period.
```{r}
series.01a%>%
    filter(series_id=='CES0000000001')
```
```{r}
series.01a%>%
    filter(series_id=='CES0000000001') %>%
    select(-footnote_codes) %>%
    group_by(series_id, year, period) %>%
    summarise_all(sum)
```

I'm very satisfied with these comparisons, where grouping and summarizing the row count remains equal. I'd like to test that each year and period occurs exactly once.  

## Time Series Conversion  
For reasons discussed by [Business Science](https://twitter.com/bizScienc), I'll lean on the tidyquant package for impementing time series elements with this analysis.  
My conversion to date solution was inspired by this stackoverflow [post](https://stackoverflow.com/questions/6242955/converting-year-and-month-yyyy-mm-format-to-a-date/6242980).

```{r}
library(tidyquant)
```

Here, I use zoo::as.yearmon to convert the year and period fields to a more useful date field.  
```{r}
series.01a$date <- as.yearmon(paste(series.01a$year,
                                 substr(series.01a$period, 2, 4),sep="-"))
```

I filter for the series that I'm seeking, mutate a change value using dplyr::lag, and shed some fields that I don't need.
```{r}
fs <- series.01a %>%
filter(series_id=='CES0000000001') %>%
    mutate(chg=value-lag(value)) %>%
    select(date, value, chg)
```

```{r plot4}
plot(fs)
```
Inspired by tidyquant vignette, "[Charting with Tidyquant](https://cran.r-project.org/web/packages/tidyquant/vignettes/TQ04-charting-with-tidyquant.html)", from Example 3, Charting volume with geom_segment.
```{r plot5}
fs %>%
    ggplot(aes(x = date, y = chg)) +
    geom_segment(aes(xend = date, yend = 0, color = chg))
```


I'm pleased at this point because I'm very close to my objective. There are a couple of messages that have me piqued, but I'm moving on for now.

```{r plot6}
fs %>%
    filter(date > 2007) %>%
    ggplot(aes(x = date, y = chg)) +
    geom_segment(aes(xend = date, yend = 0, color = chg)) + 
    labs(title="Monthly jobs growth", subtitle="In thousands", y="", x="") + 
    theme_light() +
    theme(legend.position="none")
```

There is one more issue to resolve where the date field is being evaluated as continuous, and it's causing the x-axis to line up very poorly. I think that I need to convert it from yearmon to date.

```{r plot7}
fs %>%
    mutate(date2=as.Date(date)) %>%
    filter(date > 2007) %>%
    ggplot(aes(x = date2, y = chg)) +
    geom_segment(aes(xend = date2, yend = 0, color = chg)) + 
    labs(title="Monthly jobs growth", subtitle="In thousands", y="", x="") + 
    theme_light() +
    theme(legend.position="none")
```

To conclude, the full code to produce the same chart from start to finish.
```{r plot8}
library(tidyverse)
library(tidyquant)
url <- "https://download.bls.gov/pub/time.series/ce/ce.data.01a.CurrentSeasAE"
series.01a <- read_tsv(url)

series.01a$date <- as.yearmon(paste(series.01a$year,
                                 substr(series.01a$period, 2, 4),sep="-"))
fs <- series.01a %>%
    filter(series_id=='CES0000000001') %>%
    mutate(chg=value-lag(value)) %>%
    select(date, value, chg)

fs %>%
    mutate(date2=as.Date(date)) %>%
    filter(date > 2007) %>%
    ggplot(aes(x = date2, y = chg)) +
    geom_segment(aes(xend = date2, yend = 0, color = chg)) + 
    labs(title="Monthly jobs growth", subtitle="In thousands", y="", x="") + 
    theme_light() +
    theme(legend.position="none")  

```

